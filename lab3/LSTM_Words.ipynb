{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T13:19:00.333390Z",
     "iopub.status.busy": "2024-05-26T13:19:00.332935Z",
     "iopub.status.idle": "2024-05-26T13:19:02.393303Z",
     "shell.execute_reply": "2024-05-26T13:19:02.392687Z",
     "shell.execute_reply.started": "2024-05-26T13:19:00.333370Z"
    },
    "id": "EvyxcS-gmU2R",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 13:19:00.507811: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 13:19:01.258254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow import keras\n",
    "from typing import Dict, Tuple\n",
    "import re\n",
    "import keras.layers as l\n",
    "from keras import models, callbacks, utils, losses\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T13:19:02.394707Z",
     "iopub.status.busy": "2024-05-26T13:19:02.394253Z",
     "iopub.status.idle": "2024-05-26T13:22:14.661258Z",
     "shell.execute_reply": "2024-05-26T13:22:14.660755Z",
     "shell.execute_reply.started": "2024-05-26T13:19:02.394687Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T13:22:14.662346Z",
     "iopub.status.busy": "2024-05-26T13:22:14.661959Z",
     "iopub.status.idle": "2024-05-26T13:22:17.940710Z",
     "shell.execute_reply": "2024-05-26T13:22:17.940075Z",
     "shell.execute_reply.started": "2024-05-26T13:22:14.662326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_letters = set(\"ёйцукенгшщзхъфывапролджэячсмитьбюЁЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЯЧСМИТЬБЮ\" + string.printable)\n",
    "dirname = \"books\"\n",
    "\n",
    "text = []\n",
    "for subdir in os.listdir(dirname):\n",
    "    for text_file in os.listdir(f\"{dirname}/{subdir}\"):\n",
    "        if not re.match(r\"[a-zA-Z_0-9]+.txt\", text_file):\n",
    "            continue\n",
    "        with open(f\"{dirname}/{subdir}/{text_file}\") as f:\n",
    "            text.extend([ch for ch in f.read() if ch in valid_letters])\n",
    "text = \"\".join(text)[:2_000_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T13:22:17.942237Z",
     "iopub.status.busy": "2024-05-26T13:22:17.941899Z",
     "iopub.status.idle": "2024-05-26T13:22:19.110815Z",
     "shell.execute_reply": "2024-05-26T13:22:19.110180Z",
     "shell.execute_reply.started": "2024-05-26T13:22:17.942213Z"
    },
    "id": "h808pCammmwI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 13:22:18.278711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79262 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:8c:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "def get_features_target(seq: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    features = seq[:-1]\n",
    "    target = seq[1:]\n",
    "    return features, target\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "words = list(filter(None, [re.sub('[^а-яА-ЯёЁ0-9 ,-]', '', s).strip() for s in text.split('.')]))\n",
    "alphabet = np.array(sorted(set(' '.join(words).split(' '))))\n",
    "\n",
    "word_index = {char: i for i, char in enumerate(alphabet)}\n",
    "index_word = {i: char for i, char in enumerate(alphabet)}\n",
    "\n",
    "sequences = Dataset.from_tensor_slices(np.array([word_index[word] for word in ' '.join(words).split()])).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = sequences.map(get_features_target)\n",
    "\n",
    "data = dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "data = data.prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-26T13:53:10.792647Z",
     "iopub.status.busy": "2024-05-26T13:53:10.791633Z",
     "iopub.status.idle": "2024-05-26T14:23:15.810816Z",
     "shell.execute_reply": "2024-05-26T14:23:15.809644Z",
     "shell.execute_reply.started": "2024-05-26T13:53:10.792623Z"
    },
    "id": "rH7Bjz_gEwU-",
    "outputId": "a59489b2-d7b1-4c6c-ed9c-34e1ed7cab8d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 13:53:11.040279: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-26 13:53:11.041668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-26 13:53:11.042906: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 13:53:11.241902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-26 13:53:11.244460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-26 13:53:11.245962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-05-26 13:53:11.756017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-26 13:53:11.757927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-26 13:53:11.759737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 54s 174ms/step - loss: 8.8210 - accuracy: 0.0309\n",
      "Epoch 2/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 7.7430 - accuracy: 0.0516\n",
      "Epoch 3/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 7.0704 - accuracy: 0.0667\n",
      "Epoch 4/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 6.4844 - accuracy: 0.0793\n",
      "Epoch 5/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 6.1703 - accuracy: 0.0902\n",
      "Epoch 6/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 5.8159 - accuracy: 0.1071\n",
      "Epoch 7/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 5.4185 - accuracy: 0.1270\n",
      "Epoch 8/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 5.0489 - accuracy: 0.1585\n",
      "Epoch 9/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 4.5425 - accuracy: 0.2109\n",
      "Epoch 10/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 3.9609 - accuracy: 0.2858\n",
      "Epoch 11/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 3.4058 - accuracy: 0.3593\n",
      "Epoch 12/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 2.8663 - accuracy: 0.4359\n",
      "Epoch 13/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 2.3475 - accuracy: 0.5160\n",
      "Epoch 14/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 1.9125 - accuracy: 0.5891\n",
      "Epoch 15/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 1.5156 - accuracy: 0.6595\n",
      "Epoch 16/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 1.2074 - accuracy: 0.7178\n",
      "Epoch 17/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 0.9660 - accuracy: 0.7653\n",
      "Epoch 18/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.7821 - accuracy: 0.8040\n",
      "Epoch 19/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 0.6184 - accuracy: 0.8414\n",
      "Epoch 20/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.4785 - accuracy: 0.8743\n",
      "Epoch 21/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 0.3651 - accuracy: 0.9031\n",
      "Epoch 22/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.2691 - accuracy: 0.9286\n",
      "Epoch 23/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.2056 - accuracy: 0.9457\n",
      "Epoch 24/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.1648 - accuracy: 0.9566\n",
      "Epoch 25/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.1267 - accuracy: 0.9673\n",
      "Epoch 26/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.1032 - accuracy: 0.9738\n",
      "Epoch 27/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.0844 - accuracy: 0.9790\n",
      "Epoch 28/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.0745 - accuracy: 0.9812\n",
      "Epoch 29/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 0.0581 - accuracy: 0.9860\n",
      "Epoch 30/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.0498 - accuracy: 0.9878\n",
      "Epoch 31/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.0458 - accuracy: 0.9884\n",
      "Epoch 32/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.0415 - accuracy: 0.9896\n",
      "Epoch 33/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 0.0416 - accuracy: 0.9899\n",
      "Epoch 34/35\n",
      "299/299 [==============================] - 52s 172ms/step - loss: 0.0402 - accuracy: 0.9896\n",
      "Epoch 35/35\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 0.0346 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b4970f5b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    l.Embedding(len(alphabet), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),\n",
    "    l.LSTM(512, return_sequences=True, stateful=True),\n",
    "    l.Dense(len(alphabet) / 2, activation='relu'),\n",
    "    l.Dense(len(alphabet))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.fit(data, epochs=35, verbose=1, steps_per_epoch= len(sequences) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:38:02.234358Z",
     "iopub.status.busy": "2024-05-26T14:38:02.233326Z",
     "iopub.status.idle": "2024-05-26T14:38:02.267678Z",
     "shell.execute_reply": "2024-05-26T14:38:02.267Z",
     "shell.execute_reply.started": "2024-05-26T14:38:02.234332Z"
    },
    "id": "qPRCuF4jtcrQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_next(sample: str, model: keras.Sequential, tokenizer: Dict[str, int], vocabulary: Dict[int, str], n_next: int, temperature: float, batch_size: int, word: bool = False) -> str:\n",
    "    if word:\n",
    "        sample_vector = [tokenizer[word] for word in sample.split()]\n",
    "    else:\n",
    "        sample_vector = [tokenizer[char] for char in sample]\n",
    "    predicted = sample_vector\n",
    "    sample_tensor = tf.expand_dims(sample_vector, 0)\n",
    "    sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "    for i in range(n_next):\n",
    "        pred = model(sample_tensor)\n",
    "        pred = pred[0].numpy() / temperature\n",
    "        pred = tf.random.categorical(pred, num_samples=1)[-1, 0].numpy()\n",
    "        predicted.append(pred)\n",
    "        sample_tensor = predicted[-99:]\n",
    "        sample_tensor = tf.expand_dims([pred], 0)\n",
    "        sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "    pred_seq = [vocabulary[i] for i in predicted]\n",
    "    generated = ' '.join(pred_seq) if word else ''.join(pred_seq)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-26T14:40:58.845141Z",
     "iopub.status.busy": "2024-05-26T14:40:58.844718Z",
     "iopub.status.idle": "2024-05-26T14:40:59.685309Z",
     "shell.execute_reply": "2024-05-26T14:40:59.684546Z",
     "shell.execute_reply.started": "2024-05-26T14:40:58.845109Z"
    },
    "id": "mif8PcHiGzv3",
    "outputId": "e8e3da3b-3dd5-498d-d20f-a0f10a7495e9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что же девушка в руках Но тот самый спичечный коробок, ради колени и под этими листьями обнаженная женщина, снаружи остаются лишь руки и ноги налетает ветер, и открывается лицо и лицо это превращается неожиданно на лицо он уже не от ног Меня Смысл Однако тот самый добычу меня с пианино и это делает их Или же хоть ее для нее в этом случае, который не\n"
     ]
    }
   ],
   "source": [
    "print(predict_next(\n",
    "    sample='Что',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=64,\n",
    "    temperature=0.95,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-26T14:40:40.109818Z",
     "iopub.status.busy": "2024-05-26T14:40:40.109424Z",
     "iopub.status.idle": "2024-05-26T14:40:40.951912Z",
     "shell.execute_reply": "2024-05-26T14:40:40.951076Z",
     "shell.execute_reply.started": "2024-05-26T14:40:40.109797Z"
    },
    "id": "s4BA_0irxMui",
    "outputId": "eb317c03-0d5e-4a3d-aeb5-6ec15c8abb3d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Где я не думаю, что он не в силах сомкнуть глаз, поэтому хотя я проснулся совсем недавно, так и не смог выспаться как следует Но это время еще ничего когда я проснулся, то обнаружил, что белье и брюки в два с половиной раза в нем установлено множество телефонов-автоматов По рассказам очевидцев, этот человек примерно полдня сидел в одной и той же позе, но в течение\n"
     ]
    }
   ],
   "source": [
    "print(predict_next(\n",
    "    sample='Где',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=64,\n",
    "    temperature=0.9,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-26T14:41:03.974010Z",
     "iopub.status.busy": "2024-05-26T14:41:03.973596Z",
     "iopub.status.idle": "2024-05-26T14:41:04.835375Z",
     "shell.execute_reply": "2024-05-26T14:41:04.834313Z",
     "shell.execute_reply.started": "2024-05-26T14:41:03.973988Z"
    },
    "id": "1nbrkLYzxRPV",
    "outputId": "7d4ad326-8cba-4d95-c39f-03f77f55cfbe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Когда если ты не был на свою силы и, чтобы скрыть свое вины, безвозвратно один человек, и с таким смешением Предвкушая жареную креветку, человек выплюнет еду и меня он с такой глупости, чтобы, в нее отходы только потому, что в него нет Если бы было ни денег, то, может быть, мне бы я не в силах больше ждать Действительно, ждать невыносимо И тем не менее\n"
     ]
    }
   ],
   "source": [
    "print(predict_next(\n",
    "    sample='Когда',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=64,\n",
    "    temperature=0ю8,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
